{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpCCLTmDhcQ_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,log_loss,jaccard_score,roc_auc_score,classification_report,confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7y2x_72mh47P",
    "outputId": "69c1024c-4513-42a7-b760-8761137522c0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yHBqBhGm-wG"
   },
   "source": [
    "# **Dataset Loading**\n",
    "**Task C\tHS type detection**\n",
    "slander, \\\n",
    "religion, \\\n",
    "gender, \\\n",
    "callToViolence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "L8aAdMDmPktd",
    "outputId": "54ac0b62-6d36-4be1-bfcb-c32db2b67bcd"
   },
   "outputs": [],
   "source": [
    "# Read the csv file into a DataFrame\n",
    "train_data = pd.read_csv(\"/content/drive/MyDrive/Bangla_Hate_Speech/train.csv\")\n",
    "\n",
    "# Display the DataFrame\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EpPXuN6mGoh",
    "outputId": "4b8a3a9c-fe02-4c95-f496-b627742369b1"
   },
   "outputs": [],
   "source": [
    "# Display the count of each label\n",
    "label_counts = train_data['hate speech'].value_counts()\n",
    "print(\"\\nLabel counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZsRJ27UGiB7C",
    "outputId": "b3675599-93d1-40ee-aba4-8e93695fdd41"
   },
   "outputs": [],
   "source": [
    "# Read the excel file into a DataFrame\n",
    "test_data = pd.read_csv(\"/content/drive/MyDrive/Bangla_Hate_Speech/test.csv\")\n",
    "\n",
    "# Display the DataFrame\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8s_UIbj0mKf5",
    "outputId": "dce81e78-ba68-468a-c719-680ecd3ec3b4"
   },
   "outputs": [],
   "source": [
    "# Display the count of each label\n",
    "label_counts = test_data['hate speech'].value_counts()\n",
    "print(\"\\nLabel counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "PR9dGueDRSBE",
    "outputId": "f3a5e851-e976-41c6-92f9-2b175ad9c647"
   },
   "outputs": [],
   "source": [
    "# Read the excel file into a DataFrame\n",
    "val_data = pd.read_csv(\"/content/drive/MyDrive/Bangla_Hate_Speech/val.csv\")\n",
    "\n",
    "# Display the DataFrame\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBEda56c3U_g",
    "outputId": "3076f046-3152-4f08-8e47-710190f6b568"
   },
   "outputs": [],
   "source": [
    "# Display the count of each label\n",
    "label_counts = val_data['hate speech'].value_counts()\n",
    "print(\"\\nLabel counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6M99tZnRpdC",
    "outputId": "bcbe05c7-5824-479f-8979-e233ff5ebf9a"
   },
   "outputs": [],
   "source": [
    "# Display the shapes of the splits\n",
    "print(f\"Training set shape: {train_data.shape}\")\n",
    "print(f\"Validation set shape: {val_data.shape}\")\n",
    "print(f\"Test set shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaIoScyCznU-",
    "outputId": "607326e7-d5cb-4d6b-df11-77195abcc8ae"
   },
   "outputs": [],
   "source": [
    "print(f\"Length of train dataset: {len(train_data)}\")\n",
    "print(f\"Length of test dataset: {len(test_data)}\")\n",
    "print(f\"Length of validation dataset: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMdPz2c9GkPU"
   },
   "source": [
    "# **Custom Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBsNpLBbxutl"
   },
   "outputs": [],
   "source": [
    "class BanglaHateSpeechDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=150):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        content = self.data.iloc[idx]['sentence']\n",
    "        label = self.data.iloc[idx]['hate speech']\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            content,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11UrYcBqC4m_",
    "outputId": "8ffc73af-8b2e-4bbd-bcba-51168d05da28"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/csebuetnlp/normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP6-xV1nC5Fo",
    "outputId": "7ad19702-6eca-4426-a5cf-5f929682b2a8"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRkXL79GC5KW",
    "outputId": "1fb93ed5-a301-410f-d0da-2efaca509ecb"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "crwbxj6oC86u",
    "outputId": "1285ec9f-9717-49f7-96c5-560df4b5822f"
   },
   "outputs": [],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kErGt9ZpGwoJ"
   },
   "source": [
    "# **sahajBERT model and its tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkgKQFwB0T-m",
    "outputId": "4aa425df-bc6c-4006-adc3-3afd68bad1d5"
   },
   "outputs": [],
   "source": [
    "# Model loading\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
    "from normalizer import normalize # pip install git+https://github.com/csebuetnlp/normalizer\n",
    "num_classes = 2  #number of classes in our dataset\n",
    "\n",
    "model_name = \"neuropark/sahajBERT\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aLIRdgbyWOq",
    "outputId": "1bd8caff-d3ed-483e-bb1f-6844deb9c0ee"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7Xez_VJGThM"
   },
   "source": [
    "# **Apply normalization to the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYQpkUjCGSUC"
   },
   "outputs": [],
   "source": [
    "# Apply normalization to the datasets\n",
    "train_data['sentence'] = train_data['sentence'].apply(normalize)\n",
    "test_data['sentence'] = test_data['sentence'].apply(normalize)\n",
    "val_data['sentence'] = val_data['sentence'].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9-MGZkeG4-0"
   },
   "source": [
    "# **Custom dataset and dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-tLeV43ynJu"
   },
   "outputs": [],
   "source": [
    "# Define custom datasets\n",
    "train_dataset = BanglaHateSpeechDataset(train_data, tokenizer)\n",
    "val_dataset = BanglaHateSpeechDataset(val_data, tokenizer)\n",
    "test_dataset = BanglaHateSpeechDataset(test_data, tokenizer)\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47cXtXdL_nMo"
   },
   "source": [
    "# **Train Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20zI6bRN_bFu",
    "outputId": "319c354f-62b4-49d6-e7e6-ca2d57a27944"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in train_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pZ42AGhB26D"
   },
   "source": [
    "# **Test Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SYoY4WyfBtc5",
    "outputId": "ffe9a1a6-4b4c-4996-b39c-110718828e90"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in test_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMZs9N5zB6Vk"
   },
   "source": [
    "# **Validation Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4vKjTD1BtqP",
    "outputId": "fc62a056-3199-4cb5-d015-8532e0ec07da"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in val_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGPRkviKBl6z"
   },
   "source": [
    "# **Train Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2QNeEF0_juI",
    "outputId": "8491421a-705f-47ff-8288-7ddd90821159"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in train_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = labels.item()  # Assuming labels are single integers\n",
    "    print(\"Label:\", decoded_labels)\n",
    "\n",
    "    # Break out of the loop after processing the first sample from the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZlYAfUVCJcB"
   },
   "source": [
    "# **Test Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "md_OyaoxCDWx",
    "outputId": "467fc883-10be-4c5a-d2cf-ce719aee1b6c"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in test_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = labels.item()  # Assuming labels are single integers\n",
    "    print(\"Label:\", decoded_labels)\n",
    "\n",
    "    # Break out of the loop after processing the first sample from the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiqthc3zCQCc"
   },
   "source": [
    "# **Validation Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7jR08HkCDcb",
    "outputId": "554f57b8-e693-4453-d7af-9a87c7633af6"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in val_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = labels.item()  # Assuming labels are single integers\n",
    "    print(\"Label:\", decoded_labels)\n",
    "\n",
    "    # Break out of the loop after processing the first sample from the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcpL2A4_GSiU"
   },
   "source": [
    "# **Optimizer and Loss Function**\n",
    "## **Class Weighting:**\n",
    "Use class weights to give more importance to the minority class during training. This can help the model to focus more on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zusl9Tf-1gmX"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "learning_rate = 2e-5\n",
    "# Define the optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_data['hate speech']), y=train_data['hate speech'])\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define the loss function with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUjXcnbuGVwN"
   },
   "source": [
    "# **Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8C0VQyb1gs4",
    "outputId": "d8b7df98-b4c3-41f7-df44-3f153efb162e"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 15\n",
    "gradient_accumulation_steps = 4  # Accumulate gradients over 4 steps\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Start time of the epoch\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Wrap train_loader with tqdm for progress bar\n",
    "    for batch_idx, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Logits directly from the model output\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Average training loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    # Wrap val_loader with tqdm for progress bar\n",
    "    for batch in tqdm(val_loader, desc=f'Validation', leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Logits directly from the model output\n",
    "\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "\n",
    "        val_preds.extend(predicted.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Calculate and print epoch training time\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch + 1} completed in {epoch_time // 60:.0f}m {epoch_time % 60:.0f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWaLvTInGDsm"
   },
   "source": [
    "# **Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "by3TpLW11gwW",
    "outputId": "96f73ee3-d78f-4f55-dad3-3e9429a38611"
   },
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "test_labels = []\n",
    "test_probs = []  # Store predicted probabilities\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Assuming our model directly outputs logits\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)  # Softmax to get probabilities\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_probs.extend(probabilities.cpu().numpy())  # Append predicted probabilities\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "test_precision = precision_score(test_labels, test_preds, average='macro')\n",
    "test_recall = recall_score(test_labels, test_preds, average='macro')\n",
    "test_f1 = f1_score(test_labels, test_preds, average='macro')\n",
    "test_jaccard_score = jaccard_score(test_labels, test_preds, average='macro')\n",
    "test_log_loss = log_loss(test_labels, test_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAZtet934_WM",
    "outputId": "1f252fb2-9ba0-4adc-ec4f-8a01d0289ad9"
   },
   "outputs": [],
   "source": [
    "print(test_preds)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMJnxfow5B6E"
   },
   "source": [
    "# **Printing the evaluation metric results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k46PXStc4yhY",
    "outputId": "76eb71fa-e668-4faa-d266-5d96ca27f545"
   },
   "outputs": [],
   "source": [
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1}')\n",
    "print(f'Test Jaccard Score: {test_jaccard_score}')\n",
    "print(f'Log Loss: {test_log_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0V70hhKF_W1"
   },
   "source": [
    "# **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c0C5Q4mbybt",
    "outputId": "022047b8-40fd-4796-c149-8b72fbbc8c34"
   },
   "outputs": [],
   "source": [
    "# Mapping numeric labels to category names\n",
    "label_map = {0: 'not hate speech', 1: 'hate speech'}\n",
    "\n",
    "# Convert numeric predictions to label names\n",
    "predicted_labels = [label_map[pred] for pred in test_preds]\n",
    "true_labels = [label_map[label] for label in test_labels]\n",
    "\n",
    "# Generate and print the classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLlqZy6zHT-2"
   },
   "source": [
    "# **Confusion Matrix of Bangla Fake News**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "7LAaopHgGZrx",
    "outputId": "ff8f2ba3-b469-409d-8f88-cec4cf9f9579"
   },
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Define the custom palette\n",
    "custom_palette = sns.color_palette(\"blend:#7AB,#EDA\", as_cmap=True)# Modify the number based on number of classes in the dataset\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "\n",
    "# Create heatmap with annotations and colormap\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette, linecolor='white',\\\n",
    "                      xticklabels=['not hate speech', 'hate speech'], \\\n",
    "                      yticklabels=['not hate speech', 'hate speech'], \\\n",
    "                      annot_kws={\"family\": \"Serif\",'weight': 'bold', 'size': 12})\n",
    "\n",
    "# Set x and y labels with the custom font dictionary\n",
    "heatmap.set_xlabel('Predicted Labels', fontdict=font)\n",
    "heatmap.set_ylabel('True Labels', fontdict=font)\n",
    "heatmap.set_title('Bangla Hate Speech Detection', fontdict=font)\n",
    "\n",
    "# Set font properties for tick labels on both axes\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=12)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwfk74VtF5_i"
   },
   "source": [
    "# **Store predicted results to a csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hR1jVzjFAVsW"
   },
   "outputs": [],
   "source": [
    "# Combine the lists into a DataFrame\n",
    "data = {'Content': test_data['sentence'],\n",
    "        'True_Labels': test_data['hate speech'],\n",
    "        'Predicted_Labels': test_preds}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('sahajBERT_predicted_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKmzr6JUCwxb"
   },
   "source": [
    "# **save model, tokenizer, and classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "76GYXJkmCtOh",
    "outputId": "d38c5038-48ca-4d60-b029-1d55ad852e09"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('/content/drive/MyDrive/Bangla_Aggressive_Text/Bangla_Aggressive_Text_BanglaBERT/Bangla_Aggressive_Text_BanglaBERT_Model.pt')\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('/content/drive/MyDrive/Bangla_Aggressive_Text/Bangla_Aggressive_Text_BanglaBERT/Bangla_Aggressive_Text_BanglaBERT_Tokenizer.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97CRLpZdE7gR"
   },
   "source": [
    "# **load model, tokenizer, and classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sE__b493E03Q",
    "outputId": "8893a6e8-06a4-4b65-eed7-6257eff1e1dc"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model.from_pretrained('/content/drive/MyDrive/Bangla_Aggressive_Text/Bangla_Aggressive_Text_BanglaBERT/Bangla_Aggressive_Text_BanglaBERT_Model.pt')\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer.from_pretrained('/content/drive/MyDrive/Bangla_Aggressive_Text/Bangla_Aggressive_Text_BanglaBERT/Bangla_Aggressive_Text_BanglaBERT_Tokenizer.json')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
