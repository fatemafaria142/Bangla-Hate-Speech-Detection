{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpCCLTmDhcQ_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,log_loss,jaccard_score,roc_auc_score,classification_report,confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7y2x_72mh47P",
    "outputId": "cd07c949-d9c1-46ff-9673-4f4be1eb0b83"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yHBqBhGm-wG"
   },
   "source": [
    "# **Dataset Loading**\n",
    "**hate speech** (labeled as 1) or **non-hate speech** (labeled as 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "L8aAdMDmPktd",
    "outputId": "51e83fcf-65db-4b04-9ebb-5beb679c2cbc"
   },
   "outputs": [],
   "source": [
    "# Read the csv file into a DataFrame\n",
    "train_data = pd.read_excel(\"train_data.xlsx\")\n",
    "\n",
    "# Display the DataFrame\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EpPXuN6mGoh",
    "outputId": "300bcc3c-c4fb-4d9c-84ba-fc4069430030"
   },
   "outputs": [],
   "source": [
    "# Display the count of each label\n",
    "label_counts = train_data['label'].value_counts()\n",
    "print(\"\\nLabel counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZsRJ27UGiB7C",
    "outputId": "f2c39ca4-8ebe-4699-952a-922e09ae9b90"
   },
   "outputs": [],
   "source": [
    "# Read the excel file into a DataFrame\n",
    "test_data = pd.read_excel(\"test_data.xlsx\")\n",
    "\n",
    "# Display the DataFrame\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8s_UIbj0mKf5",
    "outputId": "dcf330cf-78e8-467e-fd18-041ebb0d0f1a"
   },
   "outputs": [],
   "source": [
    "# Display the count of each label\n",
    "label_counts = test_data['label'].value_counts()\n",
    "print(\"\\nLabel counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "PR9dGueDRSBE",
    "outputId": "c706208b-7797-46bc-b450-b17bffaf3060"
   },
   "outputs": [],
   "source": [
    "# Read the excel file into a DataFrame\n",
    "val_data = pd.read_excel(\"valid_data.xlsx\")\n",
    "\n",
    "# Display the DataFrame\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBEda56c3U_g",
    "outputId": "6b45f283-7e85-423c-d597-f663b212350a"
   },
   "outputs": [],
   "source": [
    "# Display the count of each label\n",
    "label_counts = val_data['label'].value_counts()\n",
    "print(\"\\nLabel counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v6M99tZnRpdC",
    "outputId": "a853664b-7c20-4394-c068-129af33f135a"
   },
   "outputs": [],
   "source": [
    "# Display the shapes of the splits\n",
    "print(f\"Training set shape: {train_data.shape}\")\n",
    "print(f\"Validation set shape: {val_data.shape}\")\n",
    "print(f\"Test set shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaIoScyCznU-",
    "outputId": "0c9af4ee-b3c3-48a7-df32-ca217a40c817"
   },
   "outputs": [],
   "source": [
    "print(f\"Length of train dataset: {len(train_data)}\")\n",
    "print(f\"Length of test dataset: {len(test_data)}\")\n",
    "print(f\"Length of validation dataset: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMdPz2c9GkPU"
   },
   "source": [
    "# **Custom Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBsNpLBbxutl"
   },
   "outputs": [],
   "source": [
    "class BanglaHateSpeechDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=150):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        content = self.data.iloc[idx]['post']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            content,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11UrYcBqC4m_",
    "outputId": "dba57001-a55c-4bcb-dbd5-e0ca09972133"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/csebuetnlp/normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sP6-xV1nC5Fo",
    "outputId": "9690d681-6268-42c9-8152-5d75d3897841"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRkXL79GC5KW",
    "outputId": "ed90361d-7867-4819-b96f-860292178ec1"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "crwbxj6oC86u",
    "outputId": "aa444ab0-a8cd-4c6f-9207-68487a560d5d"
   },
   "outputs": [],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kErGt9ZpGwoJ"
   },
   "source": [
    "# **XLM-RoBERTa model and its tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkgKQFwB0T-m",
    "outputId": "44602ab8-0310-4c3f-eff8-f433c323d858"
   },
   "outputs": [],
   "source": [
    "# Model loading\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n",
    "from normalizer import normalize # pip install git+https://github.com/csebuetnlp/normalizer\n",
    "num_classes = 2  #number of classes in our dataset\n",
    "\n",
    "model_name = \"FacebookAI/xlm-roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aLIRdgbyWOq",
    "outputId": "ccd3d400-7066-4e63-cf6d-11a9bf22c69c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7Xez_VJGThM"
   },
   "source": [
    "# **Apply normalization to the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYQpkUjCGSUC"
   },
   "outputs": [],
   "source": [
    "# Apply normalization to the datasets\n",
    "train_data['post'] = train_data['post'].apply(normalize)\n",
    "test_data['post'] = test_data['post'].apply(normalize)\n",
    "val_data['post'] = val_data['post'].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9-MGZkeG4-0"
   },
   "source": [
    "# **Custom dataset and dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-tLeV43ynJu"
   },
   "outputs": [],
   "source": [
    "# Define custom datasets\n",
    "train_dataset = BanglaHateSpeechDataset(train_data, tokenizer)\n",
    "val_dataset = BanglaHateSpeechDataset(val_data, tokenizer)\n",
    "test_dataset = BanglaHateSpeechDataset(test_data, tokenizer)\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47cXtXdL_nMo"
   },
   "source": [
    "# **Train Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20zI6bRN_bFu",
    "outputId": "eefd92c3-638a-4be9-dad9-c806f8239520"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in train_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pZ42AGhB26D"
   },
   "source": [
    "# **Test Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SYoY4WyfBtc5",
    "outputId": "96cc5cbc-c0b3-4ee7-8ba8-6ee9d5ab7109"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in test_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMZs9N5zB6Vk"
   },
   "source": [
    "# **Validation Dataset Encoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4vKjTD1BtqP",
    "outputId": "5023db9e-d519-46cb-89f3-f4586706d613"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "for batch in val_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}  # Using 'batch' directly\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "\n",
    "    # Print information\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "    print(\"Labels:\", labels)\n",
    "\n",
    "\n",
    "    # Break out of the loop after processing the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGPRkviKBl6z"
   },
   "source": [
    "# **Train Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2QNeEF0_juI",
    "outputId": "31d4c613-0070-48bd-f26b-d93a62385164"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in train_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = labels.item()  # Assuming labels are single integers\n",
    "    print(\"Label:\", decoded_labels)\n",
    "\n",
    "    # Break out of the loop after processing the first sample from the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZlYAfUVCJcB"
   },
   "source": [
    "# **Test Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "md_OyaoxCDWx",
    "outputId": "e7a1d6e0-be62-4184-98a3-18055deae6d3"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in test_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = labels.item()  # Assuming labels are single integers\n",
    "    print(\"Label:\", decoded_labels)\n",
    "\n",
    "    # Break out of the loop after processing the first sample from the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiqthc3zCQCc"
   },
   "source": [
    "# **Validation Dataset Decoding Printing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7jR08HkCDcb",
    "outputId": "f3f89b18-2455-4bf1-9e55-8a58053003a0"
   },
   "outputs": [],
   "source": [
    "# Set a flag to track whether it's the first batch\n",
    "first_batch = True\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for batch in val_loader:\n",
    "    # Move inputs and labels to the GPU\n",
    "    inputs = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "    # Extract information for the first example in the batch\n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "    labels = inputs['label'][0]\n",
    "\n",
    "    # Check for problematic token IDs causing overflow error during decoding\n",
    "    problematic_ids = torch.nonzero((input_ids < 0) | (input_ids >= tokenizer.vocab_size))\n",
    "    if problematic_ids.numel() > 0:\n",
    "        print(\"Problematic Token IDs:\", input_ids[problematic_ids])\n",
    "        print(\"Problematic Token Positions:\", problematic_ids)\n",
    "        # Handle the problematic input IDs as needed\n",
    "        raise ValueError(\"Problematic token IDs detected\")\n",
    "\n",
    "    # Decode and print input text\n",
    "    decoded_input_text = tokenizer.decode(input_ids.clamp(0, tokenizer.vocab_size - 1), skip_special_tokens=True)\n",
    "    print(\"Decoded Input Text:\", decoded_input_text)\n",
    "    print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "    # Decode and print labels\n",
    "    decoded_labels = labels.item()  # Assuming labels are single integers\n",
    "    print(\"Label:\", decoded_labels)\n",
    "\n",
    "    # Break out of the loop after processing the first sample from the first batch\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcpL2A4_GSiU"
   },
   "source": [
    "# **Optimizer and Loss Function**\n",
    "## **Class Weighting:**\n",
    "Use class weights to give more importance to the minority class during training. This can help the model to focus more on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zusl9Tf-1gmX"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "learning_rate = 2e-5\n",
    "# Define the optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_data['label']), y=train_data['label'])\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define the loss function with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUjXcnbuGVwN"
   },
   "source": [
    "# **Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8C0VQyb1gs4",
    "outputId": "312cb1e4-7b49-4ff3-9047-05b8539932e0"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 15\n",
    "gradient_accumulation_steps = 4  # Accumulate gradients over 4 steps\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Start time of the epoch\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Wrap train_loader with tqdm for progress bar\n",
    "    for batch_idx, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Logits directly from the model output\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Average training loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    # Wrap val_loader with tqdm for progress bar\n",
    "    for batch in tqdm(val_loader, desc=f'Validation', leave=False):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # Logits directly from the model output\n",
    "\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "\n",
    "        val_preds.extend(predicted.cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    # Calculate and print epoch training time\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch + 1} completed in {epoch_time // 60:.0f}m {epoch_time % 60:.0f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWaLvTInGDsm"
   },
   "source": [
    "# **Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "by3TpLW11gwW",
    "outputId": "3a12a0c5-f102-40ae-d722-1f9473e96ec5"
   },
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "test_labels = []\n",
    "test_probs = []  # Store predicted probabilities\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Assuming our model directly outputs logits\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)  # Softmax to get probabilities\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "        test_preds.extend(predicted.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_probs.extend(probabilities.cpu().numpy())  # Append predicted probabilities\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "test_precision = precision_score(test_labels, test_preds, average='macro')\n",
    "test_recall = recall_score(test_labels, test_preds, average='macro')\n",
    "test_f1 = f1_score(test_labels, test_preds, average='macro')\n",
    "test_jaccard_score = jaccard_score(test_labels, test_preds, average='macro')\n",
    "test_log_loss = log_loss(test_labels, test_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAZtet934_WM",
    "outputId": "db1e2e3c-54db-4170-a9b7-f91371546fdd"
   },
   "outputs": [],
   "source": [
    "print(test_preds)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMJnxfow5B6E"
   },
   "source": [
    "# **Printing the evaluation metric results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k46PXStc4yhY",
    "outputId": "4f1c066a-e10b-440b-d0fe-2f33011a891b"
   },
   "outputs": [],
   "source": [
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test Precision: {test_precision}')\n",
    "print(f'Test Recall: {test_recall}')\n",
    "print(f'Test F1 Score: {test_f1}')\n",
    "print(f'Test Jaccard Score: {test_jaccard_score}')\n",
    "print(f'Log Loss: {test_log_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0V70hhKF_W1"
   },
   "source": [
    "# **Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBzxRGAb_11P",
    "outputId": "330ae110-9933-4a14-87c8-cc6b52a3d2a7"
   },
   "outputs": [],
   "source": [
    "# Mapping numeric labels to category names\n",
    "label_map = {0: 'non-hate', 1: 'hate'}\n",
    "\n",
    "# Convert numeric predictions to label names\n",
    "predicted_labels = [label_map[pred] for pred in test_preds]\n",
    "true_labels = [label_map[label] for label in test_labels]\n",
    "\n",
    "# Generate and print the classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLlqZy6zHT-2"
   },
   "source": [
    "# **Confusion Matrix of Bangla Fake News**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "7LAaopHgGZrx",
    "outputId": "9d02f6dd-5ed5-4878-ab33-46c79cb290ae"
   },
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Define the custom palette\n",
    "custom_palette = sns.color_palette(\"blend:#7AB,#EDA\", as_cmap=True)# Modify the number based on number of classes in the dataset\n",
    "# Define custom font dictionary for title and labels\n",
    "font = {'family': 'Serif', 'weight': 'bold', 'size': 12}\n",
    "\n",
    "# Create heatmap with annotations and colormap\n",
    "heatmap = sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=custom_palette, linecolor='white',\\\n",
    "                      xticklabels=['non-hate', 'hate'], \\\n",
    "                      yticklabels=['non-hate', 'hate'], \\\n",
    "                      annot_kws={\"family\": \"Serif\",'weight': 'bold', 'size': 12})\n",
    "\n",
    "# Set x and y labels with the custom font dictionary\n",
    "heatmap.set_xlabel('Predicted Labels', fontdict=font)\n",
    "heatmap.set_ylabel('True Labels', fontdict=font)\n",
    "heatmap.set_title('Bangla Hate Speech Detection', fontdict=font)\n",
    "\n",
    "# Set font properties for tick labels on both axes\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontname='Serif', fontsize=12)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontname='Serif', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwfk74VtF5_i"
   },
   "source": [
    "# **Store predicted results to a csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hR1jVzjFAVsW"
   },
   "outputs": [],
   "source": [
    "# Combine the lists into a DataFrame\n",
    "data = {'Content': test_data['post'],\n",
    "        'True_Labels': test_data['label'],\n",
    "        'Predicted_Labels': test_preds}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('XLMRoberta_predicted_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKmzr6JUCwxb"
   },
   "source": [
    "# **save model, tokenizer, and classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "76GYXJkmCtOh",
    "outputId": "d38c5038-48ca-4d60-b029-1d55ad852e09"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained('Bangla_Aggressive_Text_BanglaBERT_Model.pt')\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained('Bangla_Aggressive_Text_BanglaBERT_Tokenizer.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97CRLpZdE7gR"
   },
   "source": [
    "# **load model, tokenizer, and classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sE__b493E03Q",
    "outputId": "8893a6e8-06a4-4b65-eed7-6257eff1e1dc"
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model.from_pretrained('Bangla_Aggressive_Text_BanglaBERT_Model.pt')\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer.from_pretrained('Bangla_Aggressive_Text_BanglaBERT_Tokenizer.json')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
